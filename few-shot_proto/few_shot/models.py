from torch import nn
import numpy as np
import torch.nn.functional as F
import torch
from typing import Dict


##########
# Layers #
##########
class Flatten(nn.Module):
    """Converts N-dimensional Tensor of shape [batch_size, d1, d2, ..., dn] to 2-dimensional Tensor
    of shape [batch_size, d1*d2*...*dn].
    # Arguments
        input: Input tensor
    """
    def forward(self, input):
        return input.view(input.size(0), -1)

class GlobalMaxPool1d(nn.Module):
    """Performs global max pooling over the entire length of a batched 1D tensor
    # Arguments
        input: Input tensor
    """
    def forward(self, input):
        return nn.functional.max_pool1d(input, kernel_size=input.size()[2:]).view(-1, input.size(1))



class GlobalAvgPool2d(nn.Module):
    """Performs global average pooling over the entire height and width of a batched 2D tensor

    # Arguments
        input: Input tensor
    """
    def forward(self, input):
        return nn.functional.avg_pool2d(input, kernel_size=input.size()[2:]).view(-1, input.size(1))

def conv_block(in_channels: int, out_channels: int) -> nn.Module:
    """Returns a Module that performs 3x3 convolution, ReLu activation, 2x2 max pooling.
    # Arguments
        in_channels:
        out_channels:
    """
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, 3, padding=1),
        nn.BatchNorm2d(out_channels),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2)
    )


def functional_conv_block(x: torch.Tensor, weights: torch.Tensor, biases: torch.Tensor,
                          bn_weights, bn_biases) -> torch.Tensor:
    """Performs 3x3 convolution, ReLu activation, 2x2 max pooling in a functional fashion.

    # Arguments:
        x: Input Tensor for the conv block
        weights: Weights for the convolutional block
        biases: Biases for the convolutional block
        bn_weights:
        bn_biases:
    """
    x = F.conv2d(x, weights, biases, padding=1)
    x = F.batch_norm(x, running_mean=None, running_var=None, weight=bn_weights, bias=bn_biases, training=True)
    x = F.relu(x)
    x = F.max_pool2d(x, kernel_size=2, stride=2)
    return x


##########
# Models #
##########
def get_few_shot_encoder(num_input_channels=1) -> nn.Module:
    """Creates a few shot encoder as used in Matching and Prototypical Networks
    # Arguments:
        num_input_channels: Number of color channels the model expects input data to contain. Omniglot = 1,
            miniImageNet = 3
    """
    return nn.Sequential(
        conv_block(num_input_channels, 64),
        conv_block(64, 64),
        conv_block(64, 64),
        conv_block(64, 64),
        Flatten(),
    )

# def get_few_shot_encoder(num_input_channels=1) -> nn.Module:
#     """Creates a few shot encoder as used in Matching and Prototypical Networks

#     # Arguments:
#         num_input_channels: Number of color channels the model expects input data to contain. Omniglot = 1,
#             miniImageNet = 3
#     """
#     hidden = 400
#     return nn.Sequential(
#         # conv_block(num_input_channels, 64),
#         # conv_block(64, 64),
#         # conv_block(64, 64),
#         # conv_block(64, 64),
        
#         nn.Sequential(nn.Conv2d(in_channels=num_input_channels, out_channels=hidden, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False),
#                                     nn.BatchNorm2d(num_features=hidden),
#                                     nn.MaxPool2d(kernel_size=2),
#                                     nn.LeakyReLU(negative_slope=0.1, inplace=True)),
        
#         nn.Sequential(nn.Conv2d(in_channels=hidden, out_channels=int(hidden*1.5), kernel_size=(3,3), stride=(2,2), padding=(1,1), bias=False),
#                                     nn.BatchNorm2d(num_features=int(hidden*1.5)),
#                                     nn.MaxPool2d(kernel_size=2),
#                                     nn.LeakyReLU(negative_slope=0.2, inplace=True),
#                                     nn.Dropout2d(0.2)),
        
#         nn.Sequential(nn.Conv2d(in_channels=int(hidden*1.5), out_channels=hidden*2, kernel_size=(3,3), stride=(2,2), padding=(1,1), bias=True),
#                                     nn.BatchNorm2d(num_features=hidden * 2),
#                                     nn.MaxPool2d(kernel_size=2),
#                                     nn.LeakyReLU(negative_slope=0.3, inplace=True),
#                                     nn.Dropout2d(0.2)),
        
#         nn.Sequential(nn.Conv2d(in_channels=hidden*2, out_channels=hidden*4, kernel_size=(3,3), stride=(2,2), padding=(1,1), bias=True),
#                                     nn.BatchNorm2d(num_features=hidden * 4),
#                                     nn.MaxPool2d(kernel_size=2),
#                                     nn.LeakyReLU(negative_slope=0.3, inplace=True),
#                                     nn.Dropout2d(0.2)),
                           
        
#         Flatten(),
#     )


